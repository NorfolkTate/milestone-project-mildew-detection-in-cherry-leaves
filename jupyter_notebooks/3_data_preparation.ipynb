{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3594037",
   "metadata": {},
   "source": [
    "# **3 â€“ Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636d2af",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Clean and prepare image data for training\n",
    "* Ensure consistency in image dimensions and file types\n",
    "* Split data into training, validation, and test sets\n",
    "* Prepare the folder structure needed for modelling\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/dataset/raw/cherry-leaves/\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Cleaned images in appropriate folders for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c0ed6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e785c4",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a6957",
   "metadata": {},
   "source": [
    "Change the working directory from its current folder to its parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af745185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Current working directory is now: C:\\Users\\amyno\\OneDrive\\Documents\\CherryLeafProject\\milestone-project-mildew-detection-in-cherry-leaves\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_dir = r\"C:\\Users\\amyno\\OneDrive\\Documents\\CherryLeafProject\\milestone-project-mildew-detection-in-cherry-leaves\"\n",
    "\n",
    "os.chdir(project_dir)\n",
    "\n",
    "print(f\" Current working directory is now: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e8bd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amyno\\\\OneDrive\\\\Documents\\\\CherryLeafProject\\\\milestone-project-mildew-detection-in-cherry-leaves'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfa7ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b022803e",
   "metadata": {},
   "source": [
    "# Identify and remove and non image files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fa8f4",
   "metadata": {},
   "source": [
    "Whilst I expect a Kaggle dataset to be relatively uniform, any non image files could result in bugs or errors during image processing later on. This step will ensure that only files ending in .jpg, .jpeg, or .png will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a1a33",
   "metadata": {},
   "source": [
    "Define the current image path and types of data allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8425ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = os.path.join(\"inputs\", \"dataset\", \"raw\", \"cherry-leaves\")\n",
    "\n",
    "valid_extensions = [\".jpg\", \".jpeg\", \".png\"] # Code explained by stack overflow and ref. in readme (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d438b",
   "metadata": {},
   "source": [
    "Track non image files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_image_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757053f",
   "metadata": {},
   "source": [
    "For loop to loop through class folders and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac56ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for class_name in os.listdir(raw_path):\n",
    "    class_folder = os.path.join(raw_path, class_name)\n",
    "\n",
    "    for file in os.listdir(class_folder):\n",
    "        file_path = os.path.join(class_folder, file)\n",
    "\n",
    "        if not os.path.splitext(file)[1].lower() in valid_extensions: \n",
    "            non_image_files.append(file_path)\n",
    "\n",
    "non_image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ee496",
   "metadata": {},
   "source": [
    "The code returned a tupple with no contents, meaning there is no non image files to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f19c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 non image files removed.\n"
     ]
    }
   ],
   "source": [
    "for file_path in non_image_files:\n",
    "    os.remove(file_path)\n",
    "\n",
    "print(f\"{len(non_image_files)} non image files removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f1b31",
   "metadata": {},
   "source": [
    "Confirmed as no non image files as none have been deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75015c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f7cbe",
   "metadata": {},
   "source": [
    "# Check image dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e86d51",
   "metadata": {},
   "source": [
    "Check if all images in the data set are the same size as this will make it easier for the model to idetify the images and therefore make predictions. If they're not they will need to be standardised first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f991ad",
   "metadata": {},
   "source": [
    "Import image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541e4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7eb0fe",
   "metadata": {},
   "source": [
    "Track the current sizes of all images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(256, 256)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for class_name in os.listdir(raw_path):\n",
    "    class_folder = os.path.join(raw_path, class_name) # code inspired by python documentation and ref. in readme (2)\n",
    "\n",
    "    for img_name in os.listdir(class_folder):\n",
    "        img_path = os.path.join(class_folder, img_name)\n",
    "        with Image.open(img_path) as img:\n",
    "            image_sizes.append(img.size)\n",
    "\n",
    "set(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbd588",
   "metadata": {},
   "source": [
    "Every image has now been itterated over and its sizes determined and listed below. As there is only one size of 256 by 256, I can see they're all the same size. Square and 265 pixels each side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba41cad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a7355",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458c0d8",
   "metadata": {},
   "source": [
    "To ensure the best evaluation possible, the dataset will be split into 3 different folders. They will be used to train the model, validate the model and then test the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be313d01",
   "metadata": {},
   "source": [
    "The splits between the groups will be;\n",
    "* 70% training\n",
    "* 15% validation\n",
    "* 15% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1559d919",
   "metadata": {},
   "source": [
    "Import shutil for copying and manipulating files and train test split to divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8990ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c458e8d",
   "metadata": {},
   "source": [
    "Set the input and output folder and confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46278ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['healthy', 'powdery_mildew']\n"
     ]
    }
   ],
   "source": [
    "raw_dir = os.path.join(\"inputs\", \"dataset\", \"raw\", \"cherry-leaves\")\n",
    "output_base_dir = os.path.join(\"inputs\", \"dataset\") # code inspired by python documentation and ref. in readme (2)\n",
    "class_names = os.listdir(raw_dir)\n",
    "\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2af8db",
   "metadata": {},
   "source": [
    "Define the split ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76240a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7 # code provided by geeks for geeks and ref. in readme (3)\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac89f32",
   "metadata": {},
   "source": [
    "Create target folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4103d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(output_base_dir, split, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff36ad",
   "metadata": {},
   "source": [
    "Loop through each class to get list of images to split and split them into classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bafd27",
   "metadata": {},
   "source": [
    "By looping through the classes first they are now seperated before splitting into their respective groups. This ensures that it will be 70%/15%/15% of each class rather than % of the whole data which could skew the model's performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1e73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split and copied into train/val/test folders.\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    class_path = os.path.join(raw_dir, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "\n",
    "    train_imgs, temp_imgs = train_test_split(images, test_size=(1 - train_ratio), random_state=42)\n",
    "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
    "\n",
    "    for split, img_list in [(\"train\", train_imgs), (\"val\", val_imgs), (\"test\", test_imgs)]:\n",
    "        for img_name in img_list:\n",
    "            src = os.path.join(class_path, img_name)\n",
    "            dst = os.path.join(output_base_dir, split, class_name, img_name)\n",
    "            shutil.copy2(src, dst)  # code provided by geeks for geeks and ref. in readme (3)\n",
    "\n",
    "print(\"Dataset successfully split and copied into train/val/test folders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8502a08",
   "metadata": {},
   "source": [
    "By looping through the classes first they are now seperated before splitting into their respective groups. This ensures that it will be 70%/15%/15% of each class rather than % of the whole data which could skew the model's performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37008f",
   "metadata": {},
   "source": [
    "First split will split the full image list into 2 groups: 70% and 30% \n",
    "* The group of 70% will be used as the training data\n",
    "* The second split will further split the 30% into 2 groups of 15% to be used as test and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e2a55",
   "metadata": {},
   "source": [
    "Lastly, confirm the number of images in each class folder to verify that the dataset has been split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c21a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/healthy: 1472 images\n",
      "train/powdery_mildew: 1472 images\n",
      "val/healthy: 316 images\n",
      "val/powdery_mildew: 316 images\n",
      "test/healthy: 316 images\n",
      "test/powdery_mildew: 316 images\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for class_name in [\"healthy\", \"powdery_mildew\"]:\n",
    "        folder = os.path.join(\"inputs\", \"dataset\", split, class_name)\n",
    "        count = len(os.listdir(folder))\n",
    "        print(f\"{split}/{class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a624f",
   "metadata": {},
   "source": [
    "This confirms the data is in the correct folders and split expectedly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d652270",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79f40d",
   "metadata": {},
   "source": [
    "# Conclusions and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83d0c1",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* The dataset was successfully split into training (70%), validation (15%), and test (15%) sets\n",
    "* Both classes contain the correct number of images in each split, maintaining balance across the dataset\n",
    "* Folder structure has been created ready for model training and evaluation\n",
    "\n",
    "## Next steps\n",
    "\n",
    "* Begin data preparation for model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
