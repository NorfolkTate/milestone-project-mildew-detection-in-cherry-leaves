{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3594037",
   "metadata": {},
   "source": [
    "# **3 â€“ Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636d2af",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Clean and prepare image data for training\n",
    "* Ensure consistency in image dimensions and file types\n",
    "* Split data into training, validation, and test sets\n",
    "* Prepare the folder structure needed for modelling\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/dataset/raw/cherry-leaves/\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Cleaned images in appropriate folders for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c0ed6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e785c4",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a6957",
   "metadata": {},
   "source": [
    "Change the working directory from its current folder to its parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402f6138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amyno\\\\OneDrive\\\\Documents\\\\CherryLeafProject\\\\milestone-project-mildew-detection-in-cherry-leaves\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a0f8b",
   "metadata": {},
   "source": [
    "Make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7147c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d7370",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e8bd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amyno\\\\OneDrive\\\\Documents\\\\CherryLeafProject\\\\milestone-project-mildew-detection-in-cherry-leaves'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfa7ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b022803e",
   "metadata": {},
   "source": [
    "# Identify and remove and non image files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fa8f4",
   "metadata": {},
   "source": [
    "Whilst I expect a Kaggle dataset to be relatively uniform, any non image files could result in bugs or errors during image processing later on. This step will ensure that only files ending in .jpg, .jpeg, or .png will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a1a33",
   "metadata": {},
   "source": [
    "Define the current image path and types of data allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8425ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = os.path.join(\"inputs\", \"dataset\", \"raw\", \"cherry-leaves\")\n",
    "\n",
    "valid_extensions = [\".jpg\", \".jpeg\", \".png\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d438b",
   "metadata": {},
   "source": [
    "Track non image files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_image_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757053f",
   "metadata": {},
   "source": [
    "For loop to loop through class folders and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac56ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for class_name in os.listdir(raw_path):\n",
    "    class_folder = os.path.join(raw_path, class_name)\n",
    "\n",
    "    for file in os.listdir(class_folder):\n",
    "        file_path = os.path.join(class_folder, file)\n",
    "\n",
    "        if not os.path.splitext(file)[1].lower() in valid_extensions:\n",
    "            non_image_files.append(file_path)\n",
    "\n",
    "non_image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ee496",
   "metadata": {},
   "source": [
    "The code returned a tupple with no contents, meaning there is no non image files to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f19c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 non image files removed.\n"
     ]
    }
   ],
   "source": [
    "for file_path in non_image_files:\n",
    "    os.remove(file_path)\n",
    "\n",
    "print(f\"{len(non_image_files)} non image files removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f1b31",
   "metadata": {},
   "source": [
    "Confirmed as no non image files as none have been deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75015c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f7cbe",
   "metadata": {},
   "source": [
    "# Check image dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e86d51",
   "metadata": {},
   "source": [
    "Check if all images in the data set are the same size as this will make it easier for the model to idetify the images and therefore make predictions. If they're not they will need to be standardised first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f991ad",
   "metadata": {},
   "source": [
    "Import image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541e4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7eb0fe",
   "metadata": {},
   "source": [
    "Track the current sizes of all images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(256, 256)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for class_name in os.listdir(raw_path):\n",
    "    class_folder = os.path.join(raw_path, class_name) # code inspired by python documentation and ref. in readme\n",
    "\n",
    "    for img_name in os.listdir(class_folder):\n",
    "        img_path = os.path.join(class_folder, img_name)\n",
    "        with Image.open(img_path) as img:\n",
    "            image_sizes.append(img.size)\n",
    "\n",
    "set(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbd588",
   "metadata": {},
   "source": [
    "Every image has now been itterated over and its sizes determined and listed below. As there is only one size of 256 by 256, I can see they're all the same size. Square and 265 pixels each side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba41cad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a7355",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458c0d8",
   "metadata": {},
   "source": [
    "To ensure the best evaluation possible, the dataset will be split into 3 different folders. They will be used to train the model, validate the model and then test the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be313d01",
   "metadata": {},
   "source": [
    "The splits between the groups will be;\n",
    "* 70% training\n",
    "* 15% validation\n",
    "* 15% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1559d919",
   "metadata": {},
   "source": [
    "Import shutil for copying and manipulating files and train test split to divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8990ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c458e8d",
   "metadata": {},
   "source": [
    "Set the input and output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7817ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = os.path.join(\"inputs\", \"dataset\", \"raw\", \"cherry-leaves\")\n",
    "output_base_dir = os.path.join(\"inputs\", \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2af8db",
   "metadata": {},
   "source": [
    "Define the split ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c76240a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7 # code provided by geeks for geeks and ref. in credits at the end of this notebook\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac89f32",
   "metadata": {},
   "source": [
    "Create target folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd4fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for class_name in os.listdir(raw_dir):\n",
    "        split_dir = os.path.join(output_base_dir, split, class_name)\n",
    "        os.makedirs(split_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff36ad",
   "metadata": {},
   "source": [
    "Loop through each class to get list of images to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9d60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(raw_dir):\n",
    "    class_path = os.path.join(raw_dir, class_name)\n",
    "    images = os.listdir(class_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8502a08",
   "metadata": {},
   "source": [
    "By looping through the classes first they are now seperated before splitting into their respective groups. This ensures that it will be 70%/15%/15% of each class rather than % of the whole data which could skew the model's performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37008f",
   "metadata": {},
   "source": [
    "First split will split the full image list into 2 groups: 70% and 30% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7999db",
   "metadata": {},
   "source": [
    "The group of 70% will be used as the training data and the remaining 30% will be firther split below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a0aaca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least one array required as input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_imgs, temp_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amyno\\OneDrive\\Documents\\CherryLeafProject\\milestone-project-mildew-detection-in-cherry-leaves\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\amyno\\OneDrive\\Documents\\CherryLeafProject\\milestone-project-mildew-detection-in-cherry-leaves\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2644\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2642\u001b[0m n_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arrays)\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: At least one array required as input"
     ]
    }
   ],
   "source": [
    "train_imgs, temp_imgs = train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d6eb2",
   "metadata": {},
   "source": [
    "Second split - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs, test_imgs = train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca6504",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "* The general use of Shutil module in python was helpfully explained via geeks for geeks (ref. in readme)\n",
    "* Stack overflow provided great information on spliting data into 3 groups (ref. in readme)\n",
    "* The general idea of scikit-learns train_test_split function was helpfully explained via geeks for geeks (ref. in readme)\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
